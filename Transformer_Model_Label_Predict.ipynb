{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0j3YEsnSfgffSBJ4S22MO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup & Dependencies**"
      ],
      "metadata": {
        "id": "phXDvCpooGfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-Yz0axLoMK8",
        "outputId": "4e1dbfbb-e3be-4031-884e-60c27c54d43b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading & Frame Building**"
      ],
      "metadata": {
        "id": "_4VuDWJSoQI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(filepath, frame_size=100):\n",
        "    data = pd.read_excel(filepath)\n",
        "\n",
        "    # Normalize selected accelerometer columns\n",
        "    acc_cols = ['right acceleration X[g]', 'right acceleration Y[g]', 'right acceleration Z[g]']\n",
        "    scaler = StandardScaler()\n",
        "    data[acc_cols] = scaler.fit_transform(data[acc_cols])\n",
        "\n",
        "    labels = data['label'].values\n",
        "    class_weights = compute_class_weights(labels)\n",
        "\n",
        "    all_frames, all_labels = [], []\n",
        "\n",
        "    # Segment data into fixed-size frames\n",
        "    for i in range(0, len(data), frame_size):\n",
        "        segment = data.iloc[i:i + frame_size]\n",
        "        frame = segment[acc_cols].values.flatten()\n",
        "        label = np.bincount(segment['label']).argmax()  # Majority label for the frame\n",
        "        all_frames.append(frame)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    return np.array(all_frames), np.array(all_labels), class_weights, data\n",
        "\n",
        "\n",
        "def build_a_frame_dict(all_frames, all_labels):\n",
        "    a_frame = {i: [] for i in range(all_frames.shape[1])}\n",
        "    a_frame['label'] = []\n",
        "\n",
        "    for frame, label in zip(all_frames, all_labels):\n",
        "        for i, val in enumerate(frame):\n",
        "            a_frame[i].append(val)\n",
        "        a_frame['label'].append(label)\n",
        "\n",
        "    return pd.DataFrame(a_frame)\n",
        "\n",
        "\n",
        "def compute_class_weights(labels):\n",
        "    label_counts = np.bincount(labels)\n",
        "    total = len(labels)\n",
        "\n",
        "    # Weight = total / (2 * count) to handle class imbalance\n",
        "    weights = [total / (2 * c) if c > 0 else 0 for c in label_counts]\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "XifnRD5roP6a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset & DataLoader**"
      ],
      "metadata": {
        "id": "-_W5aX29oYue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IMUDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        # Reshape input to (samples, sequence_length=100, features=3)\n",
        "        self.X = torch.tensor(x, dtype=torch.float32).reshape(-1, 100, 3)\n",
        "        self.Y = torch.tensor(y, dtype=torch.long).squeeze()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "def prepare_dataloaders(df, batch_size=8):\n",
        "    x = df.iloc[:, :-1].values\n",
        "    y = df['label'].values\n",
        "\n",
        "    # Split into train and validation sets\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "    train_set = IMUDataset(x_train, y_train)\n",
        "    val_set = IMUDataset(x_val, y_val)\n",
        "\n",
        "    return {\n",
        "        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
        "        'val': DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "lmTeGPY_oenJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformer Model**"
      ],
      "metadata": {
        "id": "4P1U4UkZofYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaleDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        # Compute scaled dot-product attention\n",
        "        d_k = q.size(-1)\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        attn = self.softmax(scores)\n",
        "        return torch.matmul(attn, v), attn\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_head):\n",
        "        super().__init__()\n",
        "        self.n_head = n_head\n",
        "        self.attn = ScaleDotProductAttention()\n",
        "        self.qkv_proj = nn.Linear(d_model, d_model * 3)  # Combine Q, K, V projections\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        qkv = self.qkv_proj(x).reshape(B, T, self.n_head, -1).permute(2, 0, 1, 3)\n",
        "        q, k, v = torch.chunk(qkv, 3, dim=-1)\n",
        "        out, _ = self.attn(q, k, v)\n",
        "        out = out.permute(1, 2, 0, 3).reshape(B, T, C)\n",
        "        return self.out_proj(out)\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
        "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Normalize across the last dimension\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden_dim, drop_prob=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=drop_prob),\n",
        "            nn.Linear(hidden_dim, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ffn(x)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.2, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Precompute sinusoidal positional encodings\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, ffn_hidden, drop_prob=0.2):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model, ffn_hidden)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-head self-attention with residual and norm\n",
        "        _x = x\n",
        "        x = self.attn(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + _x)\n",
        "\n",
        "        # Feed-forward network with residual and norm\n",
        "        _x = x\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.norm2(x + _x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, n_head, ffn_hidden, n_layers, drop_prob=0.2):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(d_model, n_head, ffn_hidden,  drop_prob=drop_prob)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, d_model=64, n_head=2, n_layers=2, seq_len=100, ffn_hidden=128, num_classes=2, drop_prob=0.2):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(3, d_model)  # Project 3D input to model dimension\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.encoder = Encoder(d_model, n_head, ffn_hidden, n_layers, drop_prob)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(d_model * seq_len, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.encoder(x)\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "Li8nrZ6mofwu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training & Evaluation**"
      ],
      "metadata": {
        "id": "81mZbHyzopr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_and_score(outputs, targets, class_weights, metrics):\n",
        "    # Cross-entropy loss with class weights\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    metrics['loss'].append(loss.item())\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    metrics['correct'] += (preds == targets).sum().item()\n",
        "    metrics['total'] += targets.size(0)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_model(model, dataloaders, optimizer, class_weights, patience=10, num_epochs = 100):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = float('inf')\n",
        "    history = {'train': [], 'val': []}\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "        print('-' * 30)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            model.train() if phase == 'train' else model.eval()\n",
        "            metrics = {'loss': [], 'correct': 0, 'total': 0}\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = calc_loss_and_score(outputs, labels, class_weights, metrics)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "            epoch_loss = np.mean(metrics['loss'])\n",
        "            epoch_acc = 100 * metrics['correct'] / metrics['total']\n",
        "            history[phase].append((epoch_loss, epoch_acc))\n",
        "\n",
        "            # Save model if it improves on validation loss\n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    epochs_no_improve = 0\n",
        "                    print(\" Best model updated!\")\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "\n",
        "\n",
        "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"\\nEarly stopping triggered after {epoch + 1} epochs!\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def evaluate_and_plot_confusion_matrix(model, dataloader, class_names=None, save_path=None):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute performance metrics\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds, average='weighted')\n",
        "    rec = recall_score(all_labels, all_preds, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    print(\"\\nFinal Validation Metrics:\")\n",
        "    print(f\"Accuracy : {acc * 100:.2f}%\")\n",
        "    print(f\"Precision: {prec * 100:.2f}%\")\n",
        "    print(f\"Recall   : {rec * 100:.2f}%\")\n",
        "    print(f\"F1 Score : {f1 * 100:.2f}%\")\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Confusion matrix saved to: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_metrics(history):\n",
        "    # Unpack history\n",
        "    epochs = range(1, len(history['val']) + 1)\n",
        "    train_loss, train_acc = zip(*history['train'])\n",
        "    val_loss, val_acc = zip(*history['val'])\n",
        "\n",
        "    # Plot loss and accuracy trends\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    #plt.plot(epochs, train_loss, label='Train')\n",
        "    plt.plot(epochs, train_loss[:len(epochs)], label='Train')\n",
        "    plt.plot(epochs, val_loss, label='Val')\n",
        "    plt.title(\"Loss Over Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    #plt.plot(epochs, train_acc, label='Train')\n",
        "    plt.plot(epochs, train_acc[:len(epochs)], label='Train')\n",
        "    plt.plot(epochs, val_acc, label='Val')\n",
        "    plt.title(\"Accuracy Over Epochs\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SADNZdimpFzn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run Everything**"
      ],
      "metadata": {
        "id": "2LHONOVjpG2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i3sgN0ODh6Sa",
        "outputId": "f7f4677e-bf6d-4847-83fa-b4110b640ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/100\n",
            "------------------------------\n",
            "Train Loss: 0.6679 | Accuracy: 61.74%\n",
            " Best model updated!\n",
            "Val Loss: 0.6049 | Accuracy: 65.36%\n",
            "\n",
            "Epoch 2/100\n",
            "------------------------------\n",
            "Train Loss: 0.6230 | Accuracy: 64.64%\n",
            "Val Loss: 0.6786 | Accuracy: 57.68%\n",
            "\n",
            "Epoch 3/100\n",
            "------------------------------\n",
            "Train Loss: 0.6039 | Accuracy: 68.40%\n",
            "Val Loss: 0.6240 | Accuracy: 61.60%\n",
            "\n",
            "Epoch 4/100\n",
            "------------------------------\n",
            "Train Loss: 0.5822 | Accuracy: 68.87%\n",
            " Best model updated!\n",
            "Val Loss: 0.5859 | Accuracy: 73.51%\n",
            "\n",
            "Epoch 5/100\n",
            "------------------------------\n",
            "Train Loss: 0.5322 | Accuracy: 73.58%\n",
            "Val Loss: 0.5922 | Accuracy: 75.71%\n",
            "\n",
            "Epoch 6/100\n",
            "------------------------------\n",
            "Train Loss: 0.5113 | Accuracy: 75.11%\n",
            " Best model updated!\n",
            "Val Loss: 0.5211 | Accuracy: 75.24%\n",
            "\n",
            "Epoch 7/100\n",
            "------------------------------\n",
            "Train Loss: 0.4725 | Accuracy: 76.79%\n",
            " Best model updated!\n",
            "Val Loss: 0.5054 | Accuracy: 78.53%\n",
            "\n",
            "Epoch 8/100\n",
            "------------------------------\n",
            "Train Loss: 0.4467 | Accuracy: 77.70%\n",
            "Val Loss: 0.6629 | Accuracy: 69.28%\n",
            "\n",
            "Epoch 9/100\n",
            "------------------------------\n",
            "Train Loss: 0.4106 | Accuracy: 80.48%\n",
            " Best model updated!\n",
            "Val Loss: 0.4559 | Accuracy: 80.09%\n",
            "\n",
            "Epoch 10/100\n",
            "------------------------------\n",
            "Train Loss: 0.3770 | Accuracy: 81.42%\n",
            "Val Loss: 0.5398 | Accuracy: 75.55%\n",
            "\n",
            "Epoch 11/100\n",
            "------------------------------\n",
            "Train Loss: 0.3502 | Accuracy: 82.60%\n",
            "Val Loss: 0.5001 | Accuracy: 78.21%\n",
            "\n",
            "Epoch 12/100\n",
            "------------------------------\n",
            "Train Loss: 0.3413 | Accuracy: 83.69%\n",
            "Val Loss: 0.4999 | Accuracy: 79.94%\n",
            "\n",
            "Epoch 13/100\n",
            "------------------------------\n",
            "Train Loss: 0.3106 | Accuracy: 84.83%\n",
            "Val Loss: 0.4655 | Accuracy: 83.07%\n",
            "\n",
            "Epoch 14/100\n",
            "------------------------------\n",
            "Train Loss: 0.2915 | Accuracy: 85.30%\n",
            "Val Loss: 0.5076 | Accuracy: 80.56%\n",
            "\n",
            "Epoch 15/100\n",
            "------------------------------\n",
            "Train Loss: 0.2909 | Accuracy: 85.34%\n",
            "Val Loss: 0.4785 | Accuracy: 79.78%\n",
            "\n",
            "Epoch 16/100\n",
            "------------------------------\n",
            "Train Loss: 0.2684 | Accuracy: 88.20%\n",
            "Val Loss: 0.5442 | Accuracy: 81.35%\n",
            "\n",
            "Epoch 17/100\n",
            "------------------------------\n",
            "Train Loss: 0.2523 | Accuracy: 88.04%\n",
            "Val Loss: 0.4718 | Accuracy: 81.50%\n",
            "\n",
            "Epoch 18/100\n",
            "------------------------------\n",
            "Train Loss: 0.2325 | Accuracy: 88.75%\n",
            "Val Loss: 0.5841 | Accuracy: 77.90%\n",
            "\n",
            "Epoch 19/100\n",
            "------------------------------\n",
            "Train Loss: 0.2317 | Accuracy: 89.02%\n",
            "Val Loss: 0.5083 | Accuracy: 82.60%\n",
            "\n",
            "Early stopping triggered after 19 epochs!\n",
            "\n",
            "Epoch 20/100\n",
            "------------------------------\n",
            "Train Loss: 0.2147 | Accuracy: 90.08%\n",
            "\n",
            "Early stopping triggered after 20 epochs!\n",
            "\n",
            "Epoch 21/100\n",
            "------------------------------\n",
            "Train Loss: 0.2228 | Accuracy: 89.49%\n",
            "\n",
            "Early stopping triggered after 21 epochs!\n",
            "\n",
            "Epoch 22/100\n",
            "------------------------------\n",
            "Train Loss: 0.1967 | Accuracy: 91.38%\n",
            "\n",
            "Early stopping triggered after 22 epochs!\n",
            "\n",
            "Epoch 23/100\n",
            "------------------------------\n",
            "Train Loss: 0.1899 | Accuracy: 91.30%\n",
            "\n",
            "Early stopping triggered after 23 epochs!\n",
            "\n",
            "Epoch 24/100\n",
            "------------------------------\n",
            "Train Loss: 0.1897 | Accuracy: 91.02%\n",
            "\n",
            "Early stopping triggered after 24 epochs!\n",
            "\n",
            "Epoch 25/100\n",
            "------------------------------\n",
            "Train Loss: 0.2003 | Accuracy: 90.98%\n",
            "\n",
            "Early stopping triggered after 25 epochs!\n",
            "\n",
            "Epoch 26/100\n",
            "------------------------------\n",
            "Train Loss: 0.1968 | Accuracy: 90.71%\n",
            "\n",
            "Early stopping triggered after 26 epochs!\n",
            "\n",
            "Epoch 27/100\n",
            "------------------------------\n",
            "Train Loss: 0.1723 | Accuracy: 92.63%\n",
            "\n",
            "Early stopping triggered after 27 epochs!\n",
            "\n",
            "Epoch 28/100\n",
            "------------------------------\n",
            "Train Loss: 0.1772 | Accuracy: 92.40%\n",
            "\n",
            "Early stopping triggered after 28 epochs!\n",
            "\n",
            "Epoch 29/100\n",
            "------------------------------\n",
            "Train Loss: 0.1716 | Accuracy: 92.08%\n",
            "\n",
            "Early stopping triggered after 29 epochs!\n",
            "\n",
            "Epoch 30/100\n",
            "------------------------------\n",
            "Train Loss: 0.1485 | Accuracy: 92.94%\n",
            "\n",
            "Early stopping triggered after 30 epochs!\n",
            "\n",
            "Epoch 31/100\n",
            "------------------------------\n",
            "Train Loss: 0.1485 | Accuracy: 93.53%\n",
            "\n",
            "Early stopping triggered after 31 epochs!\n",
            "\n",
            "Epoch 32/100\n",
            "------------------------------\n",
            "Train Loss: 0.1436 | Accuracy: 93.69%\n",
            "\n",
            "Early stopping triggered after 32 epochs!\n",
            "\n",
            "Epoch 33/100\n",
            "------------------------------\n",
            "Train Loss: 0.1517 | Accuracy: 93.34%\n",
            "\n",
            "Early stopping triggered after 33 epochs!\n",
            "\n",
            "Epoch 34/100\n",
            "------------------------------\n",
            "Train Loss: 0.1448 | Accuracy: 93.49%\n",
            "\n",
            "Early stopping triggered after 34 epochs!\n",
            "\n",
            "Epoch 35/100\n",
            "------------------------------\n",
            "Train Loss: 0.1928 | Accuracy: 92.04%\n",
            "\n",
            "Early stopping triggered after 35 epochs!\n",
            "\n",
            "Epoch 36/100\n",
            "------------------------------\n",
            "Train Loss: 0.1314 | Accuracy: 94.12%\n",
            "\n",
            "Early stopping triggered after 36 epochs!\n",
            "\n",
            "Epoch 37/100\n",
            "------------------------------\n",
            "Train Loss: 0.1647 | Accuracy: 92.83%\n",
            "\n",
            "Early stopping triggered after 37 epochs!\n",
            "\n",
            "Epoch 38/100\n",
            "------------------------------\n",
            "Train Loss: 0.1457 | Accuracy: 93.77%\n",
            "\n",
            "Early stopping triggered after 38 epochs!\n",
            "\n",
            "Epoch 39/100\n",
            "------------------------------\n",
            "Train Loss: 0.1449 | Accuracy: 93.14%\n",
            "\n",
            "Early stopping triggered after 39 epochs!\n",
            "\n",
            "Epoch 40/100\n",
            "------------------------------\n",
            "Train Loss: 0.1387 | Accuracy: 93.77%\n",
            "\n",
            "Early stopping triggered after 40 epochs!\n",
            "\n",
            "Epoch 41/100\n",
            "------------------------------\n",
            "Train Loss: 0.1497 | Accuracy: 92.75%\n",
            "\n",
            "Early stopping triggered after 41 epochs!\n",
            "\n",
            "Epoch 42/100\n",
            "------------------------------\n",
            "Train Loss: 0.1231 | Accuracy: 94.28%\n",
            "\n",
            "Early stopping triggered after 42 epochs!\n",
            "\n",
            "Epoch 43/100\n",
            "------------------------------\n",
            "Train Loss: 0.1337 | Accuracy: 94.12%\n",
            "\n",
            "Early stopping triggered after 43 epochs!\n",
            "\n",
            "Epoch 44/100\n",
            "------------------------------\n",
            "Train Loss: 0.1197 | Accuracy: 94.43%\n",
            "\n",
            "Early stopping triggered after 44 epochs!\n",
            "\n",
            "Epoch 45/100\n",
            "------------------------------\n",
            "Train Loss: 0.1364 | Accuracy: 94.00%\n",
            "\n",
            "Early stopping triggered after 45 epochs!\n",
            "\n",
            "Epoch 46/100\n",
            "------------------------------\n",
            "Train Loss: 0.1345 | Accuracy: 94.20%\n",
            "\n",
            "Early stopping triggered after 46 epochs!\n",
            "\n",
            "Epoch 47/100\n",
            "------------------------------\n",
            "Train Loss: 0.1186 | Accuracy: 94.94%\n",
            "\n",
            "Early stopping triggered after 47 epochs!\n",
            "\n",
            "Epoch 48/100\n",
            "------------------------------\n",
            "Train Loss: 0.1472 | Accuracy: 93.61%\n",
            "\n",
            "Early stopping triggered after 48 epochs!\n",
            "\n",
            "Epoch 49/100\n",
            "------------------------------\n",
            "Train Loss: 0.1420 | Accuracy: 94.12%\n",
            "\n",
            "Early stopping triggered after 49 epochs!\n",
            "\n",
            "Epoch 50/100\n",
            "------------------------------\n",
            "Train Loss: 0.1267 | Accuracy: 94.39%\n",
            "\n",
            "Early stopping triggered after 50 epochs!\n",
            "\n",
            "Epoch 51/100\n",
            "------------------------------\n",
            "Train Loss: 0.1117 | Accuracy: 94.67%\n",
            "\n",
            "Early stopping triggered after 51 epochs!\n",
            "\n",
            "Epoch 52/100\n",
            "------------------------------\n",
            "Train Loss: 0.1051 | Accuracy: 95.14%\n",
            "\n",
            "Early stopping triggered after 52 epochs!\n",
            "\n",
            "Epoch 53/100\n",
            "------------------------------\n",
            "Train Loss: 0.1122 | Accuracy: 94.94%\n",
            "\n",
            "Early stopping triggered after 53 epochs!\n",
            "\n",
            "Epoch 54/100\n",
            "------------------------------\n",
            "Train Loss: 0.1149 | Accuracy: 94.79%\n",
            "\n",
            "Early stopping triggered after 54 epochs!\n",
            "\n",
            "Epoch 55/100\n",
            "------------------------------\n",
            "Train Loss: 0.1159 | Accuracy: 95.22%\n",
            "\n",
            "Early stopping triggered after 55 epochs!\n",
            "\n",
            "Epoch 56/100\n",
            "------------------------------\n",
            "Train Loss: 0.1384 | Accuracy: 94.32%\n",
            "\n",
            "Early stopping triggered after 56 epochs!\n",
            "\n",
            "Epoch 57/100\n",
            "------------------------------\n",
            "Train Loss: 0.1234 | Accuracy: 94.63%\n",
            "\n",
            "Early stopping triggered after 57 epochs!\n",
            "\n",
            "Epoch 58/100\n",
            "------------------------------\n",
            "Train Loss: 0.1183 | Accuracy: 95.30%\n",
            "\n",
            "Early stopping triggered after 58 epochs!\n",
            "\n",
            "Epoch 59/100\n",
            "------------------------------\n",
            "Train Loss: 0.0980 | Accuracy: 95.73%\n",
            "\n",
            "Early stopping triggered after 59 epochs!\n",
            "\n",
            "Epoch 60/100\n",
            "------------------------------\n",
            "Train Loss: 0.1105 | Accuracy: 95.14%\n",
            "\n",
            "Early stopping triggered after 60 epochs!\n",
            "\n",
            "Epoch 61/100\n",
            "------------------------------\n",
            "Train Loss: 0.1352 | Accuracy: 94.28%\n",
            "\n",
            "Early stopping triggered after 61 epochs!\n",
            "\n",
            "Epoch 62/100\n",
            "------------------------------\n",
            "Train Loss: 0.1212 | Accuracy: 94.94%\n",
            "\n",
            "Early stopping triggered after 62 epochs!\n",
            "\n",
            "Epoch 63/100\n",
            "------------------------------\n",
            "Train Loss: 0.1015 | Accuracy: 95.92%\n",
            "\n",
            "Early stopping triggered after 63 epochs!\n",
            "\n",
            "Epoch 64/100\n",
            "------------------------------\n",
            "Train Loss: 0.0941 | Accuracy: 95.88%\n",
            "\n",
            "Early stopping triggered after 64 epochs!\n",
            "\n",
            "Epoch 65/100\n",
            "------------------------------\n",
            "Train Loss: 0.0998 | Accuracy: 95.88%\n",
            "\n",
            "Early stopping triggered after 65 epochs!\n",
            "\n",
            "Epoch 66/100\n",
            "------------------------------\n",
            "Train Loss: 0.1160 | Accuracy: 95.14%\n",
            "\n",
            "Early stopping triggered after 66 epochs!\n",
            "\n",
            "Epoch 67/100\n",
            "------------------------------\n",
            "Train Loss: 0.1095 | Accuracy: 94.94%\n",
            "\n",
            "Early stopping triggered after 67 epochs!\n",
            "\n",
            "Epoch 68/100\n",
            "------------------------------\n",
            "Train Loss: 0.1017 | Accuracy: 95.77%\n",
            "\n",
            "Early stopping triggered after 68 epochs!\n",
            "\n",
            "Epoch 69/100\n",
            "------------------------------\n",
            "Train Loss: 0.1059 | Accuracy: 96.04%\n",
            "\n",
            "Early stopping triggered after 69 epochs!\n",
            "\n",
            "Epoch 70/100\n",
            "------------------------------\n",
            "Train Loss: 0.1111 | Accuracy: 95.41%\n",
            "\n",
            "Early stopping triggered after 70 epochs!\n",
            "\n",
            "Epoch 71/100\n",
            "------------------------------\n",
            "Train Loss: 0.0944 | Accuracy: 95.88%\n",
            "\n",
            "Early stopping triggered after 71 epochs!\n",
            "\n",
            "Epoch 72/100\n",
            "------------------------------\n",
            "Train Loss: 0.0846 | Accuracy: 96.20%\n",
            "\n",
            "Early stopping triggered after 72 epochs!\n",
            "\n",
            "Epoch 73/100\n",
            "------------------------------\n",
            "Train Loss: 0.0819 | Accuracy: 96.59%\n",
            "\n",
            "Early stopping triggered after 73 epochs!\n",
            "\n",
            "Epoch 74/100\n",
            "------------------------------\n",
            "Train Loss: 0.1102 | Accuracy: 95.45%\n",
            "\n",
            "Early stopping triggered after 74 epochs!\n",
            "\n",
            "Epoch 75/100\n",
            "------------------------------\n",
            "Train Loss: 0.1255 | Accuracy: 95.14%\n",
            "\n",
            "Early stopping triggered after 75 epochs!\n",
            "\n",
            "Epoch 76/100\n",
            "------------------------------\n",
            "Train Loss: 0.0990 | Accuracy: 95.81%\n",
            "\n",
            "Early stopping triggered after 76 epochs!\n",
            "\n",
            "Epoch 77/100\n",
            "------------------------------\n",
            "Train Loss: 0.0921 | Accuracy: 96.00%\n",
            "\n",
            "Early stopping triggered after 77 epochs!\n",
            "\n",
            "Epoch 78/100\n",
            "------------------------------\n",
            "Train Loss: 0.0975 | Accuracy: 95.92%\n",
            "\n",
            "Early stopping triggered after 78 epochs!\n",
            "\n",
            "Epoch 79/100\n",
            "------------------------------\n",
            "Train Loss: 0.1060 | Accuracy: 95.61%\n",
            "\n",
            "Early stopping triggered after 79 epochs!\n",
            "\n",
            "Epoch 80/100\n",
            "------------------------------\n",
            "Train Loss: 0.1010 | Accuracy: 95.73%\n",
            "\n",
            "Early stopping triggered after 80 epochs!\n",
            "\n",
            "Epoch 81/100\n",
            "------------------------------\n",
            "Train Loss: 0.0966 | Accuracy: 96.16%\n",
            "\n",
            "Early stopping triggered after 81 epochs!\n",
            "\n",
            "Epoch 82/100\n",
            "------------------------------\n",
            "Train Loss: 0.0852 | Accuracy: 96.55%\n",
            "\n",
            "Early stopping triggered after 82 epochs!\n",
            "\n",
            "Epoch 83/100\n",
            "------------------------------\n",
            "Train Loss: 0.0995 | Accuracy: 95.92%\n",
            "\n",
            "Early stopping triggered after 83 epochs!\n",
            "\n",
            "Epoch 84/100\n",
            "------------------------------\n",
            "Train Loss: 0.0894 | Accuracy: 96.39%\n",
            "\n",
            "Early stopping triggered after 84 epochs!\n",
            "\n",
            "Epoch 85/100\n",
            "------------------------------\n",
            "Train Loss: 0.0813 | Accuracy: 96.51%\n",
            "\n",
            "Early stopping triggered after 85 epochs!\n",
            "\n",
            "Epoch 86/100\n",
            "------------------------------\n",
            "Train Loss: 0.0917 | Accuracy: 95.84%\n",
            "\n",
            "Early stopping triggered after 86 epochs!\n",
            "\n",
            "Epoch 87/100\n",
            "------------------------------\n",
            "Train Loss: 0.0974 | Accuracy: 95.77%\n",
            "\n",
            "Early stopping triggered after 87 epochs!\n",
            "\n",
            "Epoch 88/100\n",
            "------------------------------\n",
            "Train Loss: 0.0986 | Accuracy: 95.69%\n",
            "\n",
            "Early stopping triggered after 88 epochs!\n",
            "\n",
            "Epoch 89/100\n",
            "------------------------------\n",
            "Train Loss: 0.1040 | Accuracy: 95.65%\n",
            "\n",
            "Early stopping triggered after 89 epochs!\n",
            "\n",
            "Epoch 90/100\n",
            "------------------------------\n",
            "Train Loss: 0.0968 | Accuracy: 95.57%\n",
            "\n",
            "Early stopping triggered after 90 epochs!\n",
            "\n",
            "Epoch 91/100\n",
            "------------------------------\n",
            "Train Loss: 0.0998 | Accuracy: 95.96%\n",
            "\n",
            "Early stopping triggered after 91 epochs!\n",
            "\n",
            "Epoch 92/100\n",
            "------------------------------\n",
            "Train Loss: 0.0951 | Accuracy: 95.77%\n",
            "\n",
            "Early stopping triggered after 92 epochs!\n",
            "\n",
            "Epoch 93/100\n",
            "------------------------------\n",
            "Train Loss: 0.0918 | Accuracy: 96.08%\n",
            "\n",
            "Early stopping triggered after 93 epochs!\n",
            "\n",
            "Epoch 94/100\n",
            "------------------------------\n",
            "Train Loss: 0.0925 | Accuracy: 96.32%\n",
            "\n",
            "Early stopping triggered after 94 epochs!\n",
            "\n",
            "Epoch 95/100\n",
            "------------------------------\n",
            "Train Loss: 0.0829 | Accuracy: 96.32%\n",
            "\n",
            "Early stopping triggered after 95 epochs!\n",
            "\n",
            "Epoch 96/100\n",
            "------------------------------\n",
            "Train Loss: 0.0862 | Accuracy: 96.28%\n",
            "\n",
            "Early stopping triggered after 96 epochs!\n",
            "\n",
            "Epoch 97/100\n",
            "------------------------------\n",
            "Train Loss: 0.0923 | Accuracy: 96.55%\n",
            "\n",
            "Early stopping triggered after 97 epochs!\n",
            "\n",
            "Epoch 98/100\n",
            "------------------------------\n",
            "Train Loss: 0.0895 | Accuracy: 96.28%\n",
            "\n",
            "Early stopping triggered after 98 epochs!\n",
            "\n",
            "Epoch 99/100\n",
            "------------------------------\n",
            "Train Loss: 0.0836 | Accuracy: 96.35%\n",
            "\n",
            "Early stopping triggered after 99 epochs!\n",
            "\n",
            "Epoch 100/100\n",
            "------------------------------\n",
            "Train Loss: 0.0762 | Accuracy: 96.55%\n",
            "\n",
            "Early stopping triggered after 100 epochs!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (100,) and (19,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2ede45622bb3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Plot training/validation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mplot_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Evaluate final model performance and save confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-bd541bc26758>\u001b[0m in \u001b[0;36mplot_metrics\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss Over Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m ) -> list[Line2D]:\n\u001b[0;32m-> 3829\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3830\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m         \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (19,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load and preprocess raw IMU data\n",
        "file_path = \"/content/drive/MyDrive/IMU/combined_data.xlsx\"\n",
        "frames, labels, class_weights, raw_data = load_and_preprocess_data(file_path)\n",
        "\n",
        "# Convert framed data into a DataFrame format for training\n",
        "df = build_a_frame_dict(frames, labels)\n",
        "num_classes = len(np.unique(labels))\n",
        "\n",
        "# Prepare dataloaders\n",
        "dataloaders = prepare_dataloaders(df, batch_size=8)\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = TransformerModel(num_classes=num_classes).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "# Train the model\n",
        "trained_model, history = train_model(\n",
        "    model,\n",
        "    dataloaders,\n",
        "    optimizer,\n",
        "    class_weights,\n",
        "    num_epochs=100,\n",
        "    patience=10,\n",
        ")\n",
        "\n",
        "# Plot training/validation metrics\n",
        "plot_metrics(history)\n",
        "\n",
        "# Evaluate final model performance and save confusion matrix\n",
        "evaluate_and_plot_confusion_matrix(\n",
        "    trained_model,\n",
        "    dataloaders['val'],\n",
        "    class_names=[str(i) for i in range(num_classes)],\n",
        "    save_path=\"/content/drive/MyDrive/IMU/confusion_matrix.png\"\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(trained_model.state_dict(), \"/content/drive/MyDrive/IMU/transformer_model_gaitAnalysis.pth\")\n"
      ]
    }
  ]
}